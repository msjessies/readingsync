import requests
import os
from datetime import datetime, timedelta, timezone
import pytz

# ç¦ç”¨ä»£ç†è®¾ç½®ï¼Œè§£å†³è¿æ¥é—®é¢˜
os.environ['HTTP_PROXY'] = ''
os.environ['HTTPS_PROXY'] = ''
os.environ['http_proxy'] = ''
os.environ['https_proxy'] = ''

# é…ç½®ä»ç¯å¢ƒå˜é‡è·å–
READWISE_TOKEN = os.getenv("READWISE_TOKEN")
TARGET_TAG = os.getenv("TARGET_TAG", "ai101")  # é»˜è®¤æ ‡ç­¾ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ä¿®æ”¹

def get_one_week_ago():
    """è·å–ä¸€å‘¨å‰çš„ISO 8601æ ¼å¼æ—¶é—´æˆ³"""
    one_week_ago = datetime.now(timezone.utc) - timedelta(days=7)
    return one_week_ago.strftime('%Y-%m-%dT%H:%M:%SZ')

def fetch_readwise_data(time_limited=True):
    """ä» Readwise API è·å–æ–‡ç« æ•°æ®å’Œé«˜äº®æ•°æ®"""
    # åˆ›å»ºä¸ä½¿ç”¨ä»£ç†çš„session
    session = requests.Session()
    session.proxies = {}
    session.trust_env = False
    
    headers = {"Authorization": f"Token {READWISE_TOKEN}"}
    
    # 1. è·å–å¸¦æœ‰æŒ‡å®šæ ‡ç­¾çš„æ–‡ç« 
    article_params = {
        "tag": TARGET_TAG, 
        "page_size": 100,
    }
    
    # å¦‚æœå¯ç”¨æ—¶é—´é™åˆ¶ï¼Œåªè·å–ä¸€å‘¨å†…æ›´æ–°çš„æ–‡æ¡£
    if time_limited:
        article_params["updated__gt"] = get_one_week_ago()
        print(f"ğŸ•’ åªè·å– {get_one_week_ago()} ä¹‹åæ›´æ–°çš„æ–‡æ¡£")
    else:
        print("ğŸ•’ è·å–æ‰€æœ‰å¸¦æ ‡ç­¾çš„æ–‡æ¡£ï¼ˆæ— æ—¶é—´é™åˆ¶ï¼‰")
    
    try:
        print("æ­£åœ¨è·å–æ–‡ç« æ•°æ®...")
        print(f"ğŸ“¡ APIè¯·æ±‚å‚æ•°: {article_params}")
        resp = session.get("https://readwise.io/api/v3/list/", headers=headers, params=article_params)
        print(f"ğŸ“¡ APIå“åº”çŠ¶æ€ç : {resp.status_code}")
        
        # æ‰“å°å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
        if resp.status_code != 200:
            print(f"ğŸ“¡ APIé”™è¯¯å“åº”: {resp.text[:500]}")
        
        resp.raise_for_status()
        articles_data = resp.json()
        
        print(f"è·å–åˆ° {len(articles_data['results'])} ç¯‡æ–‡ç« ")
        if articles_data['results']:
            print(f"ğŸ“„ æ–‡ç« ç¤ºä¾‹: {articles_data['results'][0].get('title', 'No title')}")
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ–‡ç« ID
            article_ids = [doc.get("id") for doc in articles_data['results'] if doc.get("id")]
            print(f"ğŸ“„ æ–‡ç« IDå‰5ä¸ª: {article_ids[:5]}")
        else:
            print("ğŸ“„ æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ")
        
        # 2. è·å–è¿™äº›æ–‡ç« çš„æ‰€æœ‰é«˜äº®æ•°æ®ï¼ˆä¸é™æ—¶é—´ï¼‰
        article_ids = [doc.get("id") for doc in articles_data['results'] if doc.get("id")]
        
        if not article_ids:
            print("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ç« IDï¼Œè·³è¿‡é«˜äº®è·å–")
            return articles_data, {"results": []}
        
        print(f"æ­£åœ¨è·å– {len(article_ids)} ç¯‡æ–‡ç« çš„æ‰€æœ‰é«˜äº®æ•°æ®...")
        highlight_params = {
            "category": "highlight",
            "page_size": 500,  # é«˜äº®æ•°æ®å¯èƒ½è¾ƒå¤š
            "parent_id__in": ",".join(str(id) for id in article_ids)  # ç¡®ä¿IDæ˜¯å­—ç¬¦ä¸²æ ¼å¼
        }
        
        print(f"ğŸ“¡ é«˜äº®APIè¯·æ±‚å‚æ•°: {highlight_params}")
        resp = session.get("https://readwise.io/api/v3/list/", headers=headers, params=highlight_params)
        print(f"ğŸ“¡ é«˜äº®APIå“åº”çŠ¶æ€ç : {resp.status_code}")
        
        if resp.status_code != 200:
            print(f"ğŸ“¡ é«˜äº®APIé”™è¯¯å“åº”: {resp.text[:500]}")
        
        resp.raise_for_status()
        highlights_data = resp.json()
        
        print(f"è·å–åˆ° {len(highlights_data['results'])} æ¡é«˜äº®")
        
        return articles_data, highlights_data
        
    except requests.exceptions.RequestException as e:
        print(f"è·å– Readwise æ•°æ®å¤±è´¥: {e}")
        return {"results": []}, {"results": []}
    except Exception as e:
        print(f"æ•°æ®å¤„ç†å¤±è´¥: {e}")
        return {"results": []}, {"results": []}

def group_highlights_by_parent(highlights_data):
    """æŒ‰ parent_id å½’ç»„é«˜äº®æ•°æ®"""
    highlights_by_parent = {}
    
    for highlight in highlights_data.get("results", []):
        parent_id = highlight.get("parent_id")
        if parent_id:
            if parent_id not in highlights_by_parent:
                highlights_by_parent[parent_id] = []
            highlights_by_parent[parent_id].append(highlight)
    
    print(f"æ‰¾åˆ° {len(highlights_by_parent)} ä¸ªæ–‡æ¡£æœ‰ç›¸å…³é«˜äº®")
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæœ‰é«˜äº®çš„æ–‡æ¡£ID
    if highlights_by_parent:
        print(f"ğŸ“ æœ‰é«˜äº®çš„æ–‡æ¡£IDå‰5ä¸ª: {list(highlights_by_parent.keys())[:5]}")
    return highlights_by_parent

def format_highlights_as_markdown(highlights_list):
    """å°†é«˜äº®åˆ—è¡¨æ ¼å¼åŒ–ä¸ºmarkdownæ ¼å¼"""
    if not highlights_list:
        return ""
    
    markdown_lines = []
    for i, highlight in enumerate(highlights_list, 1):
        # è·å–é«˜äº®æ–‡æœ¬
        text = highlight.get("text", "").strip()
        if text:
            # ä½¿ç”¨markdownçš„å¼•ç”¨æ ¼å¼
            markdown_lines.append(f"> {text}")
            
            # å¦‚æœæœ‰æ³¨é‡Šï¼Œæ·»åŠ æ³¨é‡Š
            note = highlight.get("note", "").strip()
            if note:
                markdown_lines.append(f"*æ³¨: {note}*")
            
            # æ·»åŠ ç©ºè¡Œåˆ†éš”ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
            if i < len(highlights_list):
                markdown_lines.append("")
    
    return "\n".join(markdown_lines)


def utc_to_beijing(utc_time_str):
    """å°†UTCæ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´"""
    if not utc_time_str:
        return ""
    try:
        # è§£æUTCæ—¶é—´
        utc_time = datetime.fromisoformat(utc_time_str.replace('Z', '+00:00'))
        # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
        beijing_tz = pytz.timezone('Asia/Shanghai')
        
        beijing_time = utc_time.astimezone(beijing_tz)
        return beijing_time.strftime('%Y-%m-%d %H:%M:%S')
    except Exception as e:
        print(f"æ—¶é—´è½¬æ¢å¤±è´¥: {e}")
        return utc_time_str


def build_feishu_fields(doc, highlights_by_parent):
    """æ„å»ºé£ä¹¦è¡¨æ ¼å­—æ®µï¼Œä½¿ç”¨åˆ†ç¦»çš„é«˜äº®æ•°æ®"""
    # è·å–è¯¥æ–‡æ¡£çš„é«˜äº®æ•°æ®
    doc_id = doc.get("id")
    doc_highlights = highlights_by_parent.get(doc_id, [])
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŒ¹é…æƒ…å†µ
    if doc_highlights:
        print(f"âœ… æ–‡æ¡£ {doc.get('title', 'Unknown')[:50]}... æ‰¾åˆ° {len(doc_highlights)} æ¡é«˜äº®")
    else:
        print(f"âŒ æ–‡æ¡£ {doc.get('title', 'Unknown')[:50]}... æœªæ‰¾åˆ°é«˜äº® (ID: {doc_id})")
    
    # å°†é«˜äº®æ ¼å¼åŒ–ä¸ºmarkdown
    highlights_markdown = format_highlights_as_markdown(doc_highlights)
    
    # è¿‡æ»¤æ‰ ai101 æ ‡ç­¾ï¼Œåªæ˜¾ç¤ºå…¶ä»–æœ‰ç”¨çš„æ ‡ç­¾
    filtered_tags = [tag for tag in doc.get("tags", []) if tag.lower() != "ai101"]
    
    return {
        "æ–‡ç« æ ‡é¢˜Article": doc.get("title", ""),
        "åˆ†ç±»Tags": filtered_tags,  # é£ä¹¦å¤šé€‰å­—æ®µéœ€è¦å­—ç¬¦ä¸²æ•°ç»„ï¼Œä¸æ˜¯é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
        "é«˜äº®Highlight": highlights_markdown,
        "æ‘˜è¦Summary": doc.get("summary", ""),
        "URL": doc.get("source_url", ""),    # åŸæ–‡url
        "åŠ å…¥æ—¶é—´UpdatedTime": utc_to_beijing(doc.get("updated", "") or doc.get("updated_at", ""))
    }

# é£ä¹¦åº”ç”¨é…ç½® - å…¨éƒ¨ä»ç¯å¢ƒå˜é‡è·å–
APP_ID = os.getenv("FEISHU_APP_ID")
APP_SECRET = os.getenv("FEISHU_APP_SECRET")
APP_TOKEN = os.getenv("FEISHU_APP_TOKEN")
TABLE_ID = os.getenv("FEISHU_TABLE_ID")

def get_tenant_access_token(app_id, app_secret):
    """è·å–é£ä¹¦ tenant_access_token"""
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    headers = {"Content-Type": "application/json; charset=utf-8"}
    payload = {
        "app_id": app_id,
        "app_secret": app_secret
    }
    
    try:
        resp = requests.post(url, headers=headers, json=payload)
        resp.raise_for_status()
        result = resp.json()
        
        if result.get("code") == 0:
            token = result.get("tenant_access_token")
            print(f"âœ“ æˆåŠŸè·å– tenant_access_token")
            return token
        else:
            print(f"âœ— è·å– tenant_access_token å¤±è´¥: {result}")
            return None
    except Exception as e:
        print(f"âœ— è·å– tenant_access_token å¼‚å¸¸: {e}")
        return None

def get_existing_records(token, app_token, table_id):
    """è·å–å·²å­˜åœ¨è®°å½•çš„è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºå»é‡å’Œæ›´æ–°åˆ¤æ–­"""
    url = f'https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records'
    headers = {'Authorization': f'Bearer {token}'}
    params = {'page_size': 500}  # è·å–æ›´å¤šè®°å½•æ¥æ£€æŸ¥é‡å¤
    
    try:
        resp = requests.get(url, headers=headers, params=params)
        resp.raise_for_status()
        result = resp.json()
        
        existing_records = {}  # URL -> {record_id, highlight, ...}
        if 'data' in result and 'items' in result['data']:
            for item in result['data']['items']:
                if 'fields' in item and 'URL' in item['fields']:
                    url = item['fields']['URL']
                    existing_records[url] = {
                        'record_id': item.get('record_id'),
                        'highlight': item['fields'].get('é«˜äº®Highlight', ''),
                        'title': item['fields'].get('æ–‡ç« æ ‡é¢˜Article', ''),
                    }
        
        return existing_records
    except Exception as e:
        print(f"è·å–å·²å­˜åœ¨è®°å½•å¤±è´¥: {e}")
        return {}

def insert_to_bitable(token, app_token, table_id, fields):
    """å‘é£ä¹¦å¤šç»´è¡¨æ ¼æ’å…¥æ•°æ®"""
    url = f'https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records'
    headers = {
        'Authorization': f'Bearer {token}',
        'Content-Type': 'application/json'
    }
    payload = {"fields": fields}
    
    try:
        resp = requests.post(url, headers=headers, json=payload)
        resp.raise_for_status()  # æ£€æŸ¥HTTPçŠ¶æ€ç 
        return resp.json()
    except requests.exceptions.RequestException as e:
        print(f"é£ä¹¦APIè°ƒç”¨å¤±è´¥: {e}")
        return {"error": str(e)}
    except Exception as e:
        print(f"æ•°æ®å¤„ç†å¤±è´¥: {e}")
        return {"error": str(e)}

def update_bitable_record(token, app_token, table_id, record_id, fields):
    """æ›´æ–°é£ä¹¦å¤šç»´è¡¨æ ¼ä¸­çš„æŒ‡å®šè®°å½•"""
    url = f'https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records/{record_id}'
    headers = {
        'Authorization': f'Bearer {token}',
        'Content-Type': 'application/json'
    }
    payload = {"fields": fields}
    
    try:
        resp = requests.put(url, headers=headers, json=payload)
        resp.raise_for_status()  # æ£€æŸ¥HTTPçŠ¶æ€ç 
        return resp.json()
    except requests.exceptions.RequestException as e:
        print(f"é£ä¹¦æ›´æ–°APIè°ƒç”¨å¤±è´¥: {e}")
        return {"error": str(e)}
    except Exception as e:
        print(f"æ›´æ–°æ•°æ®å¤„ç†å¤±è´¥: {e}")
        return {"error": str(e)}

def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„æ•°æ®åŒæ­¥æµç¨‹"""
    print("å¼€å§‹åŒæ­¥ Readwise Reader æ•°æ®åˆ°é£ä¹¦...")
    
    # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
    print(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
    print(f"- ç›®æ ‡æ ‡ç­¾: {TARGET_TAG}")
    print(f"- READWISE_TOKEN å·²é…ç½®: {'æ˜¯' if READWISE_TOKEN else 'å¦'}")
    print(f"- FEISHU_APP_ID å·²é…ç½®: {'æ˜¯' if APP_ID else 'å¦'}")
    print(f"- FEISHU_APP_SECRET å·²é…ç½®: {'æ˜¯' if APP_SECRET else 'å¦'}")
    print(f"- FEISHU_APP_TOKEN å·²é…ç½®: {'æ˜¯' if APP_TOKEN else 'å¦'}")
    print(f"- FEISHU_TABLE_ID å·²é…ç½®: {'æ˜¯' if TABLE_ID else 'å¦'}")
    print(f"- æŸ¥è¯¢æ—¶é—´èŒƒå›´: {get_one_week_ago()} åˆ°ç°åœ¨")
    
    # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
    required_vars = {
        "READWISE_TOKEN": READWISE_TOKEN,
        "FEISHU_APP_ID": APP_ID,
        "FEISHU_APP_SECRET": APP_SECRET,
        "FEISHU_APP_TOKEN": APP_TOKEN,
        "FEISHU_TABLE_ID": TABLE_ID,
    }
    
    missing_vars = [var for var, value in required_vars.items() if not value]
    if missing_vars:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        print("è¯·è®¾ç½®è¿™äº›ç¯å¢ƒå˜é‡åé‡æ–°è¿è¡Œç¨‹åº")
        return
    
    # è·å– Readwise æ•°æ® - å…ˆå°è¯•æ‰€æœ‰æ•°æ®ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
    print("æ­£åœ¨è·å– Readwise æ•°æ®...")
    data, highlights_data = fetch_readwise_data(time_limited=False)
    
    # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œå†å°è¯•ä¸€å‘¨å†…çš„æ•°æ®ï¼ˆæ’æŸ¥APIé—®é¢˜ï¼‰
    if not data["results"]:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¸¦æ ‡ç­¾çš„æ–‡æ¡£ï¼Œå°è¯•é™åˆ¶æ—¶é—´èŒƒå›´...")
        data, highlights_data = fetch_readwise_data(time_limited=True)
    
    # æŒ‰æ–‡æ¡£IDå½’ç»„é«˜äº®
    highlights_by_parent = group_highlights_by_parent(highlights_data)
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰è·å–åˆ°æ•°æ®ï¼Œç›´æ¥è¿”å›
    if not data["results"]:
        print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®ï¼Œå¯èƒ½çš„åŸå› ï¼š")
        print("  1. Readwise ä¸­æ²¡æœ‰å¸¦æœ‰æŒ‡å®šæ ‡ç­¾çš„æ–‡ç« ")
        print("  2. Readwise API è°ƒç”¨å¤±è´¥")
        print("  3. ç½‘ç»œè¿æ¥é—®é¢˜")
        print("ğŸ’¡ å»ºè®®ï¼š")
        print("  - æ£€æŸ¥ Readwise ä¸­æ˜¯å¦æœ‰å¸¦ 'ai101' æ ‡ç­¾çš„æ–‡ç« ")
        print("  - ç¡®è®¤ READWISE_TOKEN æ˜¯å¦æ­£ç¡®")
        print("  - æŸ¥çœ‹ä¸Šé¢çš„APIè°ƒç”¨è¯¦ç»†æ—¥å¿—")
        return
    
    # è·å–é£ä¹¦ tenant_access_token
    print("æ­£åœ¨è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ...")
    tenant_token = get_tenant_access_token(APP_ID, APP_SECRET)
    if not tenant_token:
        print("âŒ æ— æ³•è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œï¼Œé€€å‡ºç¨‹åº")
        return
    
    # è·å–å·²å­˜åœ¨è®°å½•çš„è¯¦ç»†ä¿¡æ¯
    print("æ­£åœ¨æ£€æŸ¥å·²å­˜åœ¨çš„è®°å½•...")
    existing_records = get_existing_records(tenant_token, APP_TOKEN, TABLE_ID)
    print(f"å‘ç° {len(existing_records)} æ¡å·²å­˜åœ¨è®°å½•")
    
    # åˆ†ç±»å¤„ç†ï¼šæ–°å¢ vs æ›´æ–°
    new_docs = []  # æ–°URLï¼Œéœ€è¦æ’å…¥
    update_docs = []  # å·²å­˜åœ¨URLï¼Œä½†highlightå¯èƒ½æœ‰æ›´æ–°
    skipped_count = 0
    
    # ä¸´æ—¶è°ƒè¯•ï¼šå¼ºåˆ¶å¤„ç†ç¬¬ä¸€ç¯‡æ–‡ç« æ¥æµ‹è¯•é«˜äº®åŒ¹é…
    debug_doc = data["results"][0] if data["results"] else None
    if debug_doc:
        print(f"ğŸ§ª è°ƒè¯•æ¨¡å¼ï¼šå¼ºåˆ¶å¤„ç†ç¬¬ä¸€ç¯‡æ–‡ç« æ¥æµ‹è¯•é«˜äº®")
        debug_fields = build_feishu_fields(debug_doc, highlights_by_parent)
        print(f"ğŸ§ª è°ƒè¯•ç»“æœ: é«˜äº®å†…å®¹é•¿åº¦ = {len(debug_fields.get('é«˜äº®Highlight', ''))}")
    
    for doc in data["results"]:
        doc_url = doc.get("source_url", "")
        if not doc_url:
            continue
            
        if doc_url in existing_records:
            # æ£€æŸ¥highlightæ˜¯å¦æœ‰æ›´æ–°
            existing_record = existing_records[doc_url]
            # è·å–è¯¥æ–‡æ¡£çš„æ–°é«˜äº®æ•°æ®
            doc_id = doc.get("id")
            doc_highlights = highlights_by_parent.get(doc_id, [])
            new_highlight = format_highlights_as_markdown(doc_highlights)
            existing_highlight = existing_record['highlight']
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºé«˜äº®æ¯”è¾ƒæƒ…å†µ
            print(f"ğŸ” æ£€æŸ¥æ–‡æ¡£: {doc.get('title', 'Unknown')[:50]}...")
            print(f"    ç°æœ‰é«˜äº®é•¿åº¦: {len(existing_highlight)}")
            print(f"    æ–°é«˜äº®é•¿åº¦: {len(new_highlight)}")
            
            if new_highlight != existing_highlight:
                print(f"ğŸ”„ å‘ç°highlightæ›´æ–°: {doc.get('title', 'Unknown')}")
                update_docs.append((doc, existing_record))
            else:
                skipped_count += 1
                print(f"âš ï¸  æ— å˜æ›´ï¼Œè·³è¿‡: {doc.get('title', 'Unknown')}")
        else:
            print(f"âœ¨ å‘ç°æ–°æ–‡æ¡£: {doc.get('title', 'Unknown')}")
            new_docs.append(doc)
    
    print(f"å…± {len(data['results'])} æ¡è®°å½•: {len(new_docs)} æ¡æ–°å¢ï¼Œ{len(update_docs)} æ¡éœ€æ›´æ–°highlightï¼Œ{skipped_count} æ¡æ— å˜æ›´")
    
    if not new_docs and not update_docs:
        print("ğŸ‰ æ²¡æœ‰è®°å½•éœ€è¦åŒæ­¥æˆ–æ›´æ–°ï¼")
        return
    
    # å¤„ç†æ–°å¢è®°å½•
    insert_success_count = 0
    if new_docs:
        print(f"\nğŸ“ å¼€å§‹å¤„ç† {len(new_docs)} æ¡æ–°å¢è®°å½•...")
        for doc in new_docs:
            feishu_fields = build_feishu_fields(doc, highlights_by_parent)
            print("æ–°å¢å†…å®¹ï¼š", feishu_fields)    # å¯é€‰ï¼šæ–¹ä¾¿ debug
            result = insert_to_bitable(tenant_token, APP_TOKEN, TABLE_ID, feishu_fields)
            
            if "error" not in result:
                insert_success_count += 1
                print(f'âœ“ æ–°å¢[{feishu_fields["æ–‡ç« æ ‡é¢˜Article"]}] æˆåŠŸ')
            else:
                print(f'âœ— æ–°å¢[{feishu_fields["æ–‡ç« æ ‡é¢˜Article"]}] å¤±è´¥:', result)
    
    # å¤„ç†highlightæ›´æ–°è®°å½•
    update_success_count = 0
    if update_docs:
        print(f"\nğŸ”„ å¼€å§‹å¤„ç† {len(update_docs)} æ¡highlightæ›´æ–°è®°å½•...")
        for doc, existing_record in update_docs:
            # åªæ›´æ–°highlightå­—æ®µ
            # è·å–è¯¥æ–‡æ¡£çš„æ–°é«˜äº®æ•°æ®
            doc_id = doc.get("id")
            doc_highlights = highlights_by_parent.get(doc_id, [])
            new_highlight = format_highlights_as_markdown(doc_highlights)
            update_fields = {"é«˜äº®Highlight": new_highlight}
            
            print(f"æ›´æ–°highlight: {existing_record['title']}")
            result = update_bitable_record(tenant_token, APP_TOKEN, TABLE_ID, existing_record['record_id'], update_fields)
            
            if "error" not in result:
                update_success_count += 1
                print(f'âœ“ æ›´æ–°[{existing_record["title"]}]çš„highlight æˆåŠŸ')
            else:
                print(f'âœ— æ›´æ–°[{existing_record["title"]}]çš„highlight å¤±è´¥:', result)
    
    print(f"\nğŸ‰ åŒæ­¥å®Œæˆï¼")
    print(f"ğŸ“Š ç»“æœç»Ÿè®¡:")
    print(f"   â€¢ æ–°å¢è®°å½•: {insert_success_count}/{len(new_docs)} æˆåŠŸ")
    print(f"   â€¢ æ›´æ–°è®°å½•: {update_success_count}/{len(update_docs)} æˆåŠŸ")
    print(f"   â€¢ æ— å˜æ›´è®°å½•: {skipped_count} æ¡")
    print(f"   â€¢ æ€»å…±è·å–: {len(data['results'])} æ¡ (è¿‡å»ä¸€å‘¨å†…æ›´æ–°)")


if __name__ == "__main__":
    main()


